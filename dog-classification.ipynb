{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Let's break the notebook into separate steps. Feel free to navigate the notebook and comment if you have any suggestions.\n\nStep 0: Import Datasets \\\nStep 1: Detect Dogs\\\nStep 2: Create a CNN to Classify Dog Breeds (from Scratch)\\\nStep 3: Create a CNN to Classify Dog Breeds (using Transfer Learning)\\\nStep 4: Test","metadata":{}},{"cell_type":"markdown","source":"# Initializations\nAt first we need to import the libraries. It is considered as standard imports.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid\n\nfrom PIL import Image\nfrom IPython.display import display\nimport cv2\nfrom PIL import ImageFile\nimport torchvision.transforms as transforms\nImageFile.LOAD_TRUNCATED_IMAGES = True  # 如果不想花时间把数据集中的破损图片找出来后删除掉, 如果文件时损坏的就跳过。\n\nimport glob   \nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline  \n# 直接在python console中生成图像 \nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-23T10:35:03.159111Z","iopub.execute_input":"2021-11-23T10:35:03.159424Z","iopub.status.idle":"2021-11-23T10:35:05.117317Z","shell.execute_reply.started":"2021-11-23T10:35:03.159347Z","shell.execute_reply":"2021-11-23T10:35:05.116356Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"We will be using this function mostly everywhere to run our experiments deterministically. Random functions of Numpy and Pandas will behave deterministically after this. To learn more about Deterministic Neural Networks please check out [this notebook](https://www.kaggle.com/bminixhofer/deterministic-neural-networks-using-pytorch)","metadata":{}},{"cell_type":"code","source":"# 设置各种随机种子\ndef seed_everything(seed=1234):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # 使用cuda保证每次结果一样\n    torch.backends.cudnn.deterministic = True\nseed_everything(42)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T10:36:40.155013Z","iopub.execute_input":"2021-11-23T10:36:40.155268Z","iopub.status.idle":"2021-11-23T10:36:40.164088Z","shell.execute_reply.started":"2021-11-23T10:36:40.155239Z","shell.execute_reply":"2021-11-23T10:36:40.162972Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:06.513973Z","iopub.execute_input":"2021-11-23T06:15:06.514597Z","iopub.status.idle":"2021-11-23T06:15:07.214189Z","shell.execute_reply.started":"2021-11-23T06:15:06.514556Z","shell.execute_reply":"2021-11-23T06:15:07.213321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Have you wondered about why they use 42? Do you want to know about the reason behind 42? Look [Here ](https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Answer_to_the_Ultimate_Question_of_Life.2C_the_Universe_and_Everything_.2842.29):p\n\n","metadata":{}},{"cell_type":"code","source":"#Read the dataset \nPATH = '../input/dog-breed-identification/'\nlabels = pd.read_csv(PATH+'labels.csv')\nprint(labels.head(5))\n# print(type(labels))  # <class 'pandas.core.frame.DataFrame'>\n# 就是去掉X中的第一个，然后再把去掉后的结果返回给X\nlabelnames = pd.read_csv(PATH + 'sample_submission.csv').keys()[1:]\n# print(type(labelnames))  # <class 'pandas.core.indexes.base.Index'>\nprint(len(labelnames)) # 120种\nprint(\"Train folder has \", len(os.listdir(PATH+'train')),'images which matches with label\\'s', len(labels),'images')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T10:36:43.795137Z","iopub.execute_input":"2021-11-23T10:36:43.795424Z","iopub.status.idle":"2021-11-23T10:36:44.651630Z","shell.execute_reply.started":"2021-11-23T10:36:43.795393Z","shell.execute_reply":"2021-11-23T10:36:44.650444Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 测试程序\n# labelnames1 = pd.read_csv(PATH + 'sample_submission.csv').keys()[1:]\n# labelnames1\nprint(labels.head())\nprint('--------------------')\n# 牵涉到pandas操作\ncodes = range(len(labelnames))\n# print(codes)  # range(0, 120)\nbreed_to_code = dict(zip(labelnames, codes))\n# print(breed_to_code)\ncode_to_breed = dict(zip(codes, labelnames))\n# print(code_to_breed)\n# labels['target'] = [breed_to_code[x] for x in labels.breed]\n# 以下等价的写法\nlabels['target'] = labels['breed'].apply(lambda x : breed_to_code[x])\nprint(labels.head())\nprint('--------------------')\nlabels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\nprint(labels_pivot.head())\nprint(labels_pivot.index)\nprint(labels_pivot.columns)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T10:36:48.414414Z","iopub.execute_input":"2021-11-23T10:36:48.415052Z","iopub.status.idle":"2021-11-23T10:36:48.488050Z","shell.execute_reply.started":"2021-11-23T10:36:48.415013Z","shell.execute_reply":"2021-11-23T10:36:48.487262Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# 牵涉到pandas操作\ncodes = range(len(labelnames))\n# print(codes)  # range(0, 120)\nbreed_to_code = dict(zip(labelnames, codes))\n# print(breed_to_code)\ncode_to_breed = dict(zip(codes, labelnames))\n# print(code_to_breed)\n# labels['target'] = [breed_to_code[x] for x in labels.breed]\n# 以下等价的写法\nlabels['target'] = labels['breed'].apply(lambda x : breed_to_code[x])\nprint(\"--------------------------\")\n# print(labels.head(10))\n# labels['rank'] = labels.groupby('breed').rank()['id']\nprint(\"--------------------------\")\n# print(labels.head(10))\n\n# pivot()方法相当于unstack()、实现二维透视，参数为（index、column、values）\nlabels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n# sample方法 分割训练集集和开发集\ntrain = labels_pivot.sample(frac=0.85)\n# print(train.iloc[3702, :])\nvalid = labels_pivot[~labels_pivot['id'].isin(train['id'])]\nprint(train.shape, valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T10:36:54.515542Z","iopub.execute_input":"2021-11-23T10:36:54.516277Z","iopub.status.idle":"2021-11-23T10:36:54.567953Z","shell.execute_reply.started":"2021-11-23T10:36:54.516236Z","shell.execute_reply":"2021-11-23T10:36:54.567254Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 测试程序\ncodes = range(len(labelnames))\nbreed_to_code_test = dict(zip(labelnames, codes))\nlabels_test = labels\nlabels_test['target'] = labels['breed'].apply(lambda x : breed_to_code_test[x])","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:24:25.527442Z","iopub.execute_input":"2021-11-22T13:24:25.527744Z","iopub.status.idle":"2021-11-22T13:24:25.541418Z","shell.execute_reply.started":"2021-11-22T13:24:25.527712Z","shell.execute_reply":"2021-11-22T13:24:25.540597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 测试程序\nlabels_test = labels_test.head(50)\ng[\"rank\"] = labels_test.groupby('breed').rank()[\"id\"]\nfor name, group in g:\n    print(name)\n    print(group)\n    print()\n# g.get_group('target')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:41:12.22737Z","iopub.execute_input":"2021-11-22T13:41:12.227631Z","iopub.status.idle":"2021-11-22T13:41:12.250966Z","shell.execute_reply.started":"2021-11-22T13:41:12.227599Z","shell.execute_reply":"2021-11-22T13:41:12.25002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 测试程序\n# codes1 = range(len(labelnames))\n# breed_to_code = dict(zip(labelnames, codes))\n# code_to_bread = dict(zip(codes, labelnames))\n# for data in breed_to_code:\n#     print(data, breed_to_code[data])\n# print('-------------------------------')\n# # for data in code_to_bread:\n# #     print(data, code_to_breed[data])\n# labels['target'] = [breed_to_code[x] for x in labels.breed]\n# print(len(labels['target']))head 10222\n# labels['rank'] = labels.groupby('breed').rank()['id']\n# print(labels['rank'])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T08:40:10.449809Z","iopub.execute_input":"2021-11-18T08:40:10.450083Z","iopub.status.idle":"2021-11-18T08:40:10.517182Z","shell.execute_reply.started":"2021-11-18T08:40:10.450055Z","shell.execute_reply":"2021-11-18T08:40:10.516377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 显示前5个labels\nprint(labels.head(5))\n# print(labels.head(10))\n# print(labels.breed[3])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:25.574283Z","iopub.execute_input":"2021-11-23T06:15:25.574819Z","iopub.status.idle":"2021-11-23T06:15:25.581803Z","shell.execute_reply.started":"2021-11-23T06:15:25.574782Z","shell.execute_reply":"2021-11-23T06:15:25.580799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:29.85798Z","iopub.execute_input":"2021-11-23T08:48:29.858411Z","iopub.status.idle":"2021-11-23T08:48:29.908027Z","shell.execute_reply.started":"2021-11-23T08:48:29.858374Z","shell.execute_reply":"2021-11-23T08:48:29.907365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the code cell below to write three separate [data loaders](http://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dog_images/train`, `dog_images/valid`, and `dog_images/test`, respectively).  You may find [this documentation on custom datasets](https://pytorch.org/vision/stable/datasets.html) to be a useful resource.  If you are interested in augmenting your training and/or validation data, check out the wide variety of [transforms](https://pytorch.org/vision/stable/transforms.html)!","metadata":{}},{"cell_type":"code","source":"# Image transformations\nimg_transform = {\n    'valid':transforms.Compose([\n        transforms.Resize(size = 256),\n        transforms.CenterCrop(size = 224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'train':transforms.Compose([\n        transforms.RandomResizedCrop(size = 256),\n        transforms.RandomRotation(degrees = 30),\n        transforms.ColorJitter(),  # 改变图像的亮度、对比度、饱和度和色调\n        transforms.RandomHorizontalFlip(),\n        transforms.CenterCrop(size=224),  \n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])  \n    ]),\n    'test':transforms.Compose([\n        transforms.Resize(size = 256),\n        transforms.CenterCrop(size = 224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:33.782022Z","iopub.execute_input":"2021-11-23T08:48:33.784262Z","iopub.status.idle":"2021-11-23T08:48:33.799472Z","shell.execute_reply.started":"2021-11-23T08:48:33.78422Z","shell.execute_reply":"2021-11-23T08:48:33.798452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I resized the pictures to 256256 and then cropped the image into 224224 randomly to avoid squashed images and normalized it using Imagenet's mean and standard deviation after converting to tensor. for train, test and valid set.\n\nFor training images, I used data augmentation which includes random rotation of 30 degrees and horizontal flip.","metadata":{}},{"cell_type":"code","source":"class DogBreedDataset(torch.utils.data.Dataset):\n    'Characterizes a dataset for PyTorch'\n    def __init__(self, img_dir, label, transform):\n        'Initialization'\n        self.img_dir = img_dir\n        self.transform = transform\n        self.label = label\n\n    def __len__(self):\n        'Denotes the total number of samples'\n        return self.label.shape[0]\n\n    def __getitem__(self, index):\n        if self.label is not None:\n            img_name = '{}.jpg'.format(self.label.iloc[index, 0])\n            fullname = self.img_dir + img_name\n            image = Image.open(fullname)\n            label = self.label.iloc[index, 1:].astype('float').to_numpy()\n            label = np.argmax(label)\n            if self.transform:\n                image = self.transform(image)\n            return [image, label]\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:38.536447Z","iopub.execute_input":"2021-11-23T08:48:38.536701Z","iopub.status.idle":"2021-11-23T08:48:38.543955Z","shell.execute_reply.started":"2021-11-23T08:48:38.536673Z","shell.execute_reply":"2021-11-23T08:48:38.542872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nnum_workers = 4\nprint(train.shape)\nprint(valid.shape)\ntrain_img = DogBreedDataset(PATH+'train/', train, transform = img_transform['train'])\nvalid_img = DogBreedDataset(PATH+'train/', valid, transform = img_transform['valid'])\n\ndataloaders={\n    'train':torch.utils.data.DataLoader(train_img, batch_size, shuffle=True),\n    'valid':torch.utils.data.DataLoader(valid_img, batch_size, shuffle=False)\n}\n# train_dataloader = torch.utils.data.DataLoader(train_img, batch_size, shuffle=True)\n# valid_dataloader = torch.utils.data.DataLoader(valid_img, batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:41.006946Z","iopub.execute_input":"2021-11-23T08:48:41.007477Z","iopub.status.idle":"2021-11-23T08:48:41.027164Z","shell.execute_reply.started":"2021-11-23T08:48:41.007432Z","shell.execute_reply":"2021-11-23T08:48:41.025976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\nuse_cuda = torch.cuda.is_available()\nprint(use_cuda)\nprint(torch.__version__)\n# !pip install torchsummary\n# from torchsummary import summary\n# !pip install pymysql","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:43.751618Z","iopub.execute_input":"2021-11-23T08:48:43.751874Z","iopub.status.idle":"2021-11-23T08:48:43.7986Z","shell.execute_reply.started":"2021-11-23T08:48:43.751845Z","shell.execute_reply":"2021-11-23T08:48:43.797797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(axis, inp):\n    \"\"\"Denormalize and show\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    axis.imshow(inp)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:46.431695Z","iopub.execute_input":"2021-11-23T08:48:46.432347Z","iopub.status.idle":"2021-11-23T08:48:46.439835Z","shell.execute_reply.started":"2021-11-23T08:48:46.432309Z","shell.execute_reply":"2021-11-23T08:48:46.439107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.axes_grid1 import ImageGrid\nimg, label = next(iter(dataloaders['train']))\nprint(img.size(), label.size())\nfig = plt.figure(1, figsize=(16, 12))\ngrid = ImageGrid(fig, 111, nrows_ncols=(8, 8), axes_pad=0.05)    \nfor i in range(img.size()[0]):\n    ax = grid[i]\n    imshow(ax, img[i])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:48:49.116358Z","iopub.execute_input":"2021-11-23T08:48:49.11683Z","iopub.status.idle":"2021-11-23T08:48:59.496812Z","shell.execute_reply.started":"2021-11-23T08:48:49.116793Z","shell.execute_reply":"2021-11-23T08:48:59.496144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Model from scratch","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# define the CNN architecture\nclass Net(nn.Module):\n    ### TODO: choose an architecture, and complete the class\n    def __init__(self):\n        super(Net, self).__init__()\n        ## Define layers of a CNN\n        \n        self.conv = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n            \n            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n            \n            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n            \n            nn.Conv2d(128, 64, kernel_size=(1, 1), stride=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n            \n            nn.Conv2d(64, 32, kernel_size=(1, 1), stride=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))              \n        )\n        \n        self.linear = nn.Sequential(\n            nn.Linear(32*7*7, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 120),\n        )\n#         # Convolution layers\n#         self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)\n#         self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n#         self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n        \n#         # Max pooling layer (divides image size by 2)\n#         self.pool = nn.MaxPool2d(2, 2)\n        \n#         # Fully connected layers\n#         self.fc1 = nn.Linear(128 * 28 * 28, 500)\n#         self.fc2 = nn.Linear(500, 120)\n        \n#         # Dropout\n#         self.dropout = nn.Dropout(0.3)\n        \n        \n    def forward(self, x):\n#         ## Define forward behavior\n        \n#         # Sequence of convolutional and max pooling layers\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.pool(F.relu(self.conv2(x)))\n#         x = self.pool(F.relu(self.conv3(x)))\n#         # Flatten image input\n#         x = x.view(-1, 128 * 28 * 28)\n#         # Dropout layer\n#         x = self.dropout(x)\n#         # 1st hidden layer, with relu activation function\n#         x = F.relu(self.fc1(x))\n#         # Dropout layer\n#         x = self.dropout(x)\n#         # 2nd hidden layer\n#         x = self.fc2(x)\n        x = self.conv(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x\n\n# instantiate the CNN\nmodel_scratch = Net()\n\n# move tensors to GPU if CUDA is available\nmodel_scratch.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:49:13.477103Z","iopub.execute_input":"2021-11-23T08:49:13.477532Z","iopub.status.idle":"2021-11-23T08:49:16.513804Z","shell.execute_reply.started":"2021-11-23T08:49:13.477495Z","shell.execute_reply":"2021-11-23T08:49:16.512988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used three convolutional layers with relu activations which are followed by maxpool layers. Also, used two fully connected layers. Between fully connected layers, dropout technique with probability = 0.25 is used to avoid the overfitting.","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:49:20.356459Z","iopub.execute_input":"2021-11-23T08:49:20.356999Z","iopub.status.idle":"2021-11-23T08:49:30.37047Z","shell.execute_reply.started":"2021-11-23T08:49:20.356961Z","shell.execute_reply":"2021-11-23T08:49:30.369376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's see the model\nfrom torchsummary import summary\nsummary(model_scratch, input_size=(3, 224, 224))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:49:30.374169Z","iopub.execute_input":"2021-11-23T08:49:30.374403Z","iopub.status.idle":"2021-11-23T08:49:36.110043Z","shell.execute_reply.started":"2021-11-23T08:49:30.374375Z","shell.execute_reply":"2021-11-23T08:49:36.10647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the next code cell to specify a [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/stable/optim.html).  ","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model_scratch.parameters(), lr=0.1, momentum = 0.9)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:49:36.114427Z","iopub.execute_input":"2021-11-23T08:49:36.11504Z","iopub.status.idle":"2021-11-23T08:49:36.125842Z","shell.execute_reply.started":"2021-11-23T08:49:36.114977Z","shell.execute_reply":"2021-11-23T08:49:36.123903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 导入SummaryWriter\nfrom torch.utils.tensorboard import SummaryWriter\n\n# 添加tensorboard\nwriter = SummaryWriter(\"./logs_dogstrain\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:50:05.992242Z","iopub.execute_input":"2021-11-23T08:50:05.992511Z","iopub.status.idle":"2021-11-23T08:50:10.407645Z","shell.execute_reply.started":"2021-11-23T08:50:05.992481Z","shell.execute_reply":"2021-11-23T08:50:10.406933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    \"\"\"returns trained model\"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf \n    # 设置训练网络的一些参数\n    # 记录训练的次数\n    total_train_step = 0\n    # 记录测试的次数\n    total_valid_step = 0\n    \n    for epoch in range(1, n_epochs+1):\n        print(\"----------第{}轮训练开始-------------\".format(epoch))\n        # initialize variables to monitor training and validation loss\n#         train_loss = 0.0\n#         valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for batch_idx, (data, target) in enumerate(loaders['train']):\n            # move to GPU\n            data, target = data.cuda(), target.cuda()\n            ## find the loss and update the model parameters accordingly\n            ## record the average training loss, using something like\n            \n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n#             train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n            total_train_step += 1\n            if (batch_idx+1) % 50 == 0:\n                print('Epoch: %d \\tBatch: %d \\tTraining Loss: %.6f' %(epoch, batch_idx + 1, loss.item()))\n                writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n                \n        ######################    \n        # validate the model #\n        ######################\n        model.eval()\n        total_valid_loss = 0.0\n        total_accuracy = 0\n        with torch.no_grad():\n            for batch_idx, (data, target) in enumerate(loaders['valid']):\n                # move to GPU\n                data, target = data.cuda(), target.cuda()\n                ## update the average validation loss\n                output = model(data)\n                loss = criterion(output, target)\n#                 valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n                total_valid_loss += loss.item()\n                accuracy = (output.argmax(1) == target).sum().item()\n                total_accuracy += accuracy\n\n            # print training/validation statistics \n#             print('Epoch: {} \\tTraining Loss: {:.4f} \\tValidation Loss: {:.4f}'.format(\n#                 epoch, \n#                 train_loss,\n#                 valid_loss\n#                 ))\n        \n            ## TODO: save the model if validation loss has decreased\n            if total_valid_loss < valid_loss_min:\n                torch.save(model.state_dict(), save_path)\n                print('BOOM! Validation loss decreased ({:.4f} --> {:.4f}).  Saving model...'.format(valid_loss_min,total_valid_loss))\n                valid_loss_min = total_valid_loss    \n        print(\"整体开发集上的loss:{}\".format(total_valid_loss))\n        print(\"整体开发集上的正确率：{}\".format(total_accuracy / valid.shape[0]))\n        writer.add_scalar(\"valid_loss\", total_valid_loss, total_valid_step)\n        writer.add_scalar(\"valid_accuracy\", total_accuracy / valid.shape[0], total_valid_step)\n        total_valid_step += 1\n\n    # return trained model\n    return model\n\n# train the model\n# model_scratch = train(20, dataloaders, model_scratch, optimizer, \n#                       criterion, use_cuda, 'model_scratch.pth')\n\n# load the model that got the best validation accuracy\n# model_scratch.load_state_dict(torch.load('model_scratch.pth'))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:50:40.00832Z","iopub.execute_input":"2021-11-23T08:50:40.008729Z","iopub.status.idle":"2021-11-23T08:50:40.030563Z","shell.execute_reply.started":"2021-11-23T08:50:40.008677Z","shell.execute_reply":"2021-11-23T08:50:40.029851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50 = train(20, dataloaders, resnet50, optimizer, criterion, use_cuda, 'model_resnet50.pth')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T08:45:39.443769Z","iopub.execute_input":"2021-11-19T08:45:39.444387Z","iopub.status.idle":"2021-11-19T08:45:40.004025Z","shell.execute_reply.started":"2021-11-19T08:45:39.444349Z","shell.execute_reply":"2021-11-19T08:45:40.002544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"as you can see it has a pretty big loss value. Training a model from scratch and getting good loss can be hard with epochs like 10. So let's move to transfer learning models which are pretrained. ","metadata":{}},{"cell_type":"code","source":"resnet50 = models.resnet50(pretrained=True)\nprint(resnet50)\nsummary(resnet50, input_size=(3, 256, 256),batch_size=-1, device='cuda')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:45:19.149941Z","iopub.execute_input":"2021-11-23T06:45:19.150801Z","iopub.status.idle":"2021-11-23T06:45:19.653632Z","shell.execute_reply.started":"2021-11-23T06:45:19.150658Z","shell.execute_reply":"2021-11-23T06:45:19.652471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##  Specify model architecture \nmodel_transfer = models.resnet50(pretrained=True)\n\n# count = 0\n# Freeze training for all \"features\" layers\nfor param in model_transfer.parameters():\n    param.requires_grad = False\n    print(param.shape)\n#     if count == 0:\n#         print(param)\n    \n# replace the last fully connected layer with a Linnear layer 133 output\nin_features = model_transfer.fc.in_features\nmodel_transfer.fc = nn.Linear(in_features, 120)\n\nif use_cuda:\n    model_transfer = model_transfer.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:51:07.238334Z","iopub.execute_input":"2021-11-23T08:51:07.238801Z","iopub.status.idle":"2021-11-23T08:51:09.460408Z","shell.execute_reply.started":"2021-11-23T08:51:07.238746Z","shell.execute_reply":"2021-11-23T08:51:09.459643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filter函数 过滤是False的，保留是True的项\ncriterion_transfer = nn.CrossEntropyLoss()\nmodel_transfer_grad_paramaters = filter(lambda p: p.requires_grad, model_transfer.parameters())\noptimizer_transfer = torch.optim.SGD(model_transfer_grad_paramaters, lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:51:24.646731Z","iopub.execute_input":"2021-11-23T08:51:24.647003Z","iopub.status.idle":"2021-11-23T08:51:24.654026Z","shell.execute_reply.started":"2021-11-23T08:51:24.646973Z","shell.execute_reply":"2021-11-23T08:51:24.652988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 测试程序\nfor param in model_transfer.parameters():\n    print(param.requires_grad, param.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:54:35.231897Z","iopub.execute_input":"2021-11-23T08:54:35.232469Z","iopub.status.idle":"2021-11-23T08:54:35.282471Z","shell.execute_reply.started":"2021-11-23T08:54:35.232431Z","shell.execute_reply":"2021-11-23T08:54:35.281692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model_transfer_grad_paramaters:\n    print(param.requires_grad, param.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:55:52.898078Z","iopub.execute_input":"2021-11-23T08:55:52.898657Z","iopub.status.idle":"2021-11-23T08:55:52.903488Z","shell.execute_reply.started":"2021-11-23T08:55:52.898619Z","shell.execute_reply":"2021-11-23T08:55:52.901915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\n# train the model\nmodel_transfer =  train(n_epochs, dataloaders, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T08:56:50.687299Z","iopub.execute_input":"2021-11-23T08:56:50.687556Z","iopub.status.idle":"2021-11-23T09:22:00.950457Z","shell.execute_reply.started":"2021-11-23T08:56:50.687528Z","shell.execute_reply":"2021-11-23T09:22:00.949613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SubmissionAdam","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(PATH+'/sample_submission.csv')\noutput = pd.DataFrame(index=submission.index, columns=submission.keys() )\noutput.head()\noutput['id'] = submission['id']\nsubmission['target'] =  [0] * len(submission)\n\n#will do this part later :3 ","metadata":{"execution":{"iopub.status.busy":"2021-11-06T10:07:32.809686Z","iopub.execute_input":"2021-11-06T10:07:32.810404Z","iopub.status.idle":"2021-11-06T10:07:33.146994Z","shell.execute_reply.started":"2021-11-06T10:07:32.81036Z","shell.execute_reply":"2021-11-06T10:07:33.14627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(PATH + './sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T10:37:50.885443Z","iopub.execute_input":"2021-11-23T10:37:50.886011Z","iopub.status.idle":"2021-11-23T10:37:51.162261Z","shell.execute_reply.started":"2021-11-23T10:37:50.885965Z","shell.execute_reply":"2021-11-23T10:37:51.161549Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"submission.columns[1:]","metadata":{"execution":{"iopub.status.busy":"2021-11-23T10:41:43.415111Z","iopub.execute_input":"2021-11-23T10:41:43.415365Z","iopub.status.idle":"2021-11-23T10:41:43.423993Z","shell.execute_reply.started":"2021-11-23T10:41:43.415336Z","shell.execute_reply":"2021-11-23T10:41:43.423335Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# 测试程序\nfor param in model_transfer.parameters():\n    param.requires_grad = True\noptimizer_all = torch.optim.SGD(model_transfer.parameters(), lr=0.01)\n# optimizer_transfer = torch.optim.SGD(model_transfer_grad_paramaters, lr=0.01)\nn_epochs = 10\n# train the model\nmodel_transfer =  train(n_epochs, dataloaders, model_transfer, optimizer_all, criterion_transfer, use_cuda, 'model_transfer.pth')\n\n# 测试代码\n# print(submission.head())\n\n# print(output.head())\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-23T09:31:21.238553Z","iopub.execute_input":"2021-11-23T09:31:21.238801Z","iopub.status.idle":"2021-11-23T09:44:14.605884Z","shell.execute_reply.started":"2021-11-23T09:31:21.238774Z","shell.execute_reply":"2021-11-23T09:44:14.605113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"count = 0\nfor param in model_transfer.parameters():\n    print(param.requires_grad, param.shape)\n    if count == 0:\n        print(param)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T09:44:14.607787Z","iopub.execute_input":"2021-11-23T09:44:14.608081Z","iopub.status.idle":"2021-11-23T09:44:15.602409Z","shell.execute_reply.started":"2021-11-23T09:44:14.608043Z","shell.execute_reply":"2021-11-23T09:44:15.601686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}